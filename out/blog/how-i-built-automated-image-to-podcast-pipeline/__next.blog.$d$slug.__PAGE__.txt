1:"$Sreact.fragment"
2:I[56454,["/_next/static/chunks/311667441357723c.js","/_next/static/chunks/5565ce82c1f7fdab.js"],"Header"]
3:I[31868,["/_next/static/chunks/311667441357723c.js","/_next/static/chunks/5565ce82c1f7fdab.js"],""]
a:I[9660,["/_next/static/chunks/311667441357723c.js","/_next/static/chunks/f7b9bcb00bd350fc.js"],"OutletBoundary"]
b:"$Sreact.suspense"
4:T48b,prose prose-invert prose-lg max-w-none prose-headings:font-semibold prose-headings:tracking-tight prose-h2:text-2xl prose-h2:mt-12 prose-h2:mb-4 prose-h3:text-xl prose-h3:mt-8 prose-h3:mb-3 prose-p:text-muted-foreground prose-p:leading-relaxed prose-a:text-accent prose-a:no-underline hover:prose-a:underline prose-strong:text-foreground prose-strong:font-semibold prose-code:text-accent prose-code:bg-secondary prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:font-mono prose-code:text-sm prose-pre:bg-card prose-pre:border prose-pre:border-border prose-pre:rounded-lg prose-blockquote:border-l-accent prose-blockquote:text-muted-foreground prose-blockquote:italic prose-ul:text-muted-foreground prose-ol:text-muted-foreground prose-li:marker:text-accent prose-img:rounded-lg prose-img:border prose-img:border-border prose-img:my-0 prose-img:w-full prose-figcaption:text-center prose-figcaption:text-sm prose-figcaption:italic prose-figcaption:text-muted-foreground/80 prose-figcaption:mt-4 prose-figcaption:leading-relaxed [&_figure]:my-12 [&_figure]:border [&_figure]:border-border/50 [&_figure]:rounded-lg [&_figure]:p-4 [&_figure]:bg-card/305:T4253,<p>About a year ago, I built a <a href="https://github.com/alexeygrigorev/kids-horror-stories-ru">Kids Horror Stories</a> project where I can take a photo of an everyday object, and the AI uses that image to write, illustrate, and narrate a short, spooky story, publishing it both <a href="https://alexeygrigorev.com/kids-horror-stories-ru/">on the website</a> and as a <a href="https://open.spotify.com/show/3vo7Q3MiEgw9ZeZBU2iDGr">podcast episode on Spotify</a> via an RSS feed.</p>
<figure>
  <img 
    src="/images/blog/kids-horror-stories/kids-horror-stories-podcast-spotify.webp" 
    alt="Kids Horror Stories podcast available on Spotify with 1200+ episodes"
    loading="lazy"
    width="1200"
    height="600"
  />
  <figcaption>Podcast on Spotify</figcaption>
</figure>
<p>Right now, the site contains 1200+ stories. All the stories are in Russian, but I translated <a href="https://alexeygrigorev.com/kids-horror-stories-ru/stories/1255-the-green-wall/">one of them</a> so you can get a sense of the format and tone.</p>
<p>In this post, I want to walk through how the project is built: its architecture, scripts, prompts, and automation.</p>
<h2>Inspiration: Storytelling With My Son</h2>
<p>This project started with my son asking for scary stories.</p>
<p>During a walk, he pointed at a parked car and asked if I could make up a horror story about it. I improvised something, and he liked it.</p>
<figure>
  <img 
    src="/images/blog/kids-horror-stories/kids-horror-stories-gemini-comic-with-son.webp" 
    alt="AI-generated comic illustration of the horror story created with my son"
    loading="lazy"
    width="1200"
    height="800"
  />
  <figcaption>I asked Gemini to make a comic about the story with my son</figcaption>
</figure>
<p>After that, he started pointing at more and more objects. At some point, I ran out of ideas.</p>
<p>When he asked for a story about a tree we passed, I did what felt natural to me: I took a photo of the tree and asked ChatGPT to write a scary story based on the image. The result was better than I expected. The tone reminded me of the short urban legends and campfire horror stories I grew up with: simple, sometimes a bit silly, but kids loved them.</p>
<p>We ended up spending the rest of the day taking photos of random objects and reading the generated stories together.</p>
<p>After a while, we had accumulated quite a few stories, and it felt wrong to leave them buried in chat history. So I decided to publish them somewhere.</p>
<h2>How I Built It</h2>
<h3>Project Website</h3>
<p>The fastest option was a static site, a small Jekyll project hosted on GitHub Pages. I already had experience with that setup, so it came together quickly.</p>
<figure>
  <img 
    src="/images/blog/kids-horror-stories/kids-horror-stories-project-website.webp" 
    alt="Kids Horror Stories project website homepage showing story listings"
    loading="lazy"
    width="1200"
    height="800"
  />
  <figcaption>Project Website</figcaption>
</figure>
<p>The first version was minimal: just photos and text stories rendered as static pages.</p>
<p>Over time, this evolved into a fully automated pipeline that now generates stories, illustrations, audio, and podcast episodes on its own.</p>
<p>Below, I'll show you how I built it.</p>
<h2>Architecture Overview</h2>
<figure>
  <img 
    src="/images/blog/kids-horror-stories/kids-horror-stories-architecture-overview.webp" 
    alt="Architecture diagram showing the complete pipeline from image input to podcast output"
    loading="lazy"
    width="1200"
    height="800"
  />
  <figcaption>Architecture Overview</figcaption>
</figure>
<p>At a high level, the system does this:</p>
<ol>
<li><strong>Input image</strong>: Either dropped into a local folder or uploaded to an <strong>S3 bucket</strong>.</li>
<li><strong>Story generation (GPT-4o)</strong>: Look at the image and generate a horror story (with title + slug) using a constrained prompt.</li>
<li><strong>Story editing (GPT-5)</strong>: Clean up grammar and phrasing in Russian.</li>
<li><strong>Illustration generation (DALL-E 3)</strong>: Use the first 1-2 paragraphs to create a prompt and generate an illustration in a consistent style.</li>
<li><strong>File organization (Jekyll)</strong>: Save markdown post with frontmatter, original image, illustration, and audio metadata.</li>
<li><strong>Audio generation (TTS)</strong>: Convert the story into speech using OpenAI TTS (tts-1, voice onyx), store audio and record metadata.</li>
<li><strong>Cleanup</strong>: Move processed images to done/, failed ones to failed/ (locally or on S3).</li>
<li><strong>Site and podcast</strong>: Jekyll builds the site. An <strong>RSS feed</strong> (XML) is updated and used by Spotify / podcast apps.</li>
</ol>
<h3>Project Layout</h3>
<p>A minimal layout looks like this:</p>
<pre><code>.
├── images_input/           # Raw incoming photos (local option)
├── images/                 # Resized images and illustrations
│   ├── XXX-slug.jpg        # AI illustration
│   └── XXX-slug-source.jpg # Original photo (resized)
├── _stories/               # Jekyll posts (.md with frontmatter)
├── assets/
│   └── audio/              # MP3 files
├── process_stories.py    # Main pipeline: image → story → illustration → files
├── generate_audio.py     # Story → TTS → MP3 + metadata
├── podcast.xml             # RSS feed for Spotify / podcast apps
└── .github/
    └── workflows/
        └── main.yml        # GitHub Actions workflow
</code></pre>
<h2>The Complete Pipeline</h2>
<p>We'll use <a href="https://alexeygrigorev.com/kids-horror-stories-ru/stories/999-silence/">this story</a> as an example. And here's the file, <a href="https://github.com/alexeygrigorev/kids-horror-stories-ru/blob/main/process_stories.py">process_stories.py</a>, with the main pipeline. The prompts I use are in Russian, but I have translated them into English for you.</p>
<p>Here's exactly how each story gets created, step by step:</p>
<h3>Step 1: Input Image</h3>
<figure>
  <img 
    src="/images/blog/kids-horror-stories/kids-horror-stories-input-photo-example.webp" 
    alt="Original photograph of everyday object used as input for story generation"
    loading="lazy"
    width="800"
    height="600"
  />
  <figcaption>Example photo - Original photograph</figcaption>
</figure>
<p>The script picks the first available image from one of two sources:</p>
<ul>
<li><strong>Local</strong>: <code>images_input/</code></li>
<li><strong>S3</strong>: <code>kids-horror-stories-ru-images/input/</code></li>
</ul>
<h3>Step 2: Story Generation from the Image (GPT-4o with Vision)</h3>
<p>The image is converted to base64 (for the chat image input) and passed to GPT-4o with this prompt:</p>
<pre><code>I want you to tell a scary story. I will send you a photograph: first, describe the photograph, and then, based on this image, come up with a horror story. Make it frightening — something in the spirit of urban folklore or urban horror legends. The ending does not have to be happy. Give the story a title.

The story should consist of 8–12 paragraphs.

For titles, do not use words such as "cursed," "curse," "gloomy," "abandoned," "mystery," "shadow," "horror," or "whisper."

Avoid plots in which characters hear rustling sounds or whispers, and also avoid plots in which objects return back to the main characters.

Do not use any formatting for either the title or the text.

The story title must be in Russian.

For the slug, use a short English title that can be used in a URL.
</code></pre>
<p>The constraints in the prompt help maintain consistency and avoid repetitive plots.</p>
<h3>Step 3: Story Editing (GPT-5)</h3>
<p>The raw story from GPT-4o is passed through GPT-5 to clean up grammar and phrasing:</p>
<pre><code>You are an experienced horror story editor with perfect command of the Russian language.

Edit this story. Make sure all grammar is clear and correct, and that there are no awkward or unnatural expressions. If you come across phrases that are not normally used in Russian, or expressions that sound unclear, replace them with ones that are more natural, commonly used, and better suited to the context of the story.

Start directly with the story. Do not include anything else in the response.
</code></pre>
<p>This keeps the style but removes awkward constructions.</p>
<h3>Step 4: Illustration Generation (DALL-E 3 + GPT-4o-mini)</h3>
<p>Next, we generate a custom illustration for the story:</p>
<ol>
<li>Extract the first two paragraphs from the final story.</li>
<li>Ask GPT-4o-mini to turn them into an English scene description in a specific style.</li>
</ol>
<p>The prompt I use:</p>
<pre><code>Based on the text from the story, create a detailed description of a single scene in English, and then generate an illustration based on that description. Use neutral references for people and animals, not proper names.

If the main character has a female name, use "woman" or "girl."
If the main character has a male name, use "man" or "boy."

If the text contains more than one scene, choose only one and create a detailed description of that scene. The description should not include a sequence of actions; instead, it should focus on describing one specific moment or setting.

The illustration will be used as a logo for a podcast episode, so the details should be shown in close-up. There should not be many objects — only the most essential elements needed to convey the scene. No more than one or two people.

Text:
{first_two_paragraphs}

Illustration style:
a flat, linear style with bold outlines and minimalistic, vibrant colors.
The scene should include whimsical and slightly eerie elements.
The overall aesthetic should combine a playful, cartoon-like feeling
with a touch of spookiness, similar to a light-hearted horror theme.

Avoid adding any text to the illustration.

Only include the final illustration prompt in your output. Do not include the scene description.
</code></pre>
<p>Feed that prompt into DALL-E 3 to get a 1024x1024 illustration. The result is downloaded, resized (e.g. 512x512, 80% quality), and stored in <code>images/</code>.</p>
<figure>
  <img 
    src="/images/blog/kids-horror-stories/kids-horror-stories-ai-illustration-earplugs.webp" 
    alt="AI-generated illustration in flat linear style with bold outlines showing whimsical horror scene"
    loading="lazy"
    width="800"
    height="800"
  />
  <figcaption>AI-generated image based on the original photo of the earplugs</figcaption>
</figure>
<h3>Step 5: File Organization &#x26; Jekyll Frontmatter</h3>
<p>Each story is assigned a sequential ID (e.g. 001, 002, …). This ID is used to build filenames and URLs.</p>
<p>Then I use the <code>save_story</code> function to produce:</p>
<ul>
<li><code>_stories/XXX-slug.md</code> – markdown post with frontmatter</li>
<li><code>images/XXX-slug.jpg</code> – AI illustration</li>
<li><code>images/XXX-slug-source.jpg</code> – original image (resized)</li>
</ul>
<p>Example frontmatter:</p>
<pre><code class="language-yaml">---
audio_size: 3539520
audio_url: https://kids-horror-stories-ru.s3.eu-west-1.amazonaws.com/audio/999-silence.mp3
date: '2025-03-23'
duration: 02:56
illustration: /images/999-silence.jpg
image_source: /images/999-silence-source.jpg
slug: 999-silence
story_number: '999'
title: Берегите тишину
---
</code></pre>
<h3>Step 6: Audio Generation (<a href="https://github.com/alexeygrigorev/kids-horror-stories-ru/blob/main/generate_audio.py">generate_audio.py</a>)</h3>
<p>Now we convert the final text into audio with OpenAI's <code>tts-1</code> model.</p>
<ol>
<li>Pass the story text and slug (e.g. <code>999-silence</code>) to <code>generate_tts</code>.</li>
<li>Upload the generated MP3 to S3 (e.g. <code>kids-horror-stories-ru-images/audio/999-silence.mp3</code>).</li>
<li>Update the story frontmatter with:
<ul>
<li><code>audio_url</code> (public S3 URL)</li>
<li><code>audio_size</code></li>
<li><code>duration</code> (you can compute from the MP3)</li>
</ul>
</li>
<li>Move the final MP3 to <code>assets/audio/</code> for GitHub Pages / Jekyll to see it.</li>
</ol>
<h3>Step 7: Cleanup</h3>
<p>After successful processing, move the original input image to <code>done/</code>. On failure, move to <code>failed/</code> and log the error.</p>
<p>This keeps the input queue clean and prevents re-processing the same image.</p>
<h3>Step 8: Podcast Feed (RSS)</h3>
<p>To get your episodes on Spotify and other podcast apps, you need an RSS XML file that lists your MP3s.</p>
<p>For that, I created <a href="https://github.com/alexeygrigorev/kids-horror-stories-ru/blob/main/podcast.xml"><code>podcast.xml</code></a>, a template for an RSS feed that Jekyll fills up for every new story.</p>
<h2>Automation with GitHub Actions</h2>
<p>I have a GitHub Actions workflow set up. It automatically pulls new images from Amazon S3, selects the first one, processes it, and publishes a new story.</p>
<p>The workflow runs on a schedule and handles the entire pipeline from image to published story and podcast episode.</p>
<h2>Tools I Used</h2>
<p>Here are the specific tools and services that made this possible:</p>
<h3>GPT-4o (Vision)</h3>
<ul>
<li>Analyzes images and generates horror stories</li>
<li>Handles the creative writing with constraints to maintain consistency</li>
</ul>
<h3>GPT-5</h3>
<ul>
<li>Edits and polishes the generated stories</li>
<li>Ensures natural Russian language and correct grammar</li>
</ul>
<h3>GPT-4o-mini</h3>
<ul>
<li>Converts story paragraphs into illustration prompts</li>
<li>Helps maintain consistent visual style</li>
</ul>
<h3>DALL-E 3</h3>
<ul>
<li>Generates custom illustrations for each story</li>
<li>Creates consistent visual style matching the podcast aesthetic</li>
</ul>
<h3>OpenAI TTS (tts-1, voice onyx)</h3>
<ul>
<li>Converts text stories into natural-sounding audio narration</li>
<li>Produces MP3 files ready for podcast distribution</li>
</ul>
<h3>Jekyll + GitHub Pages</h3>
<ul>
<li>Static site generation for the website</li>
<li>Handles markdown posts and RSS feed generation</li>
<li>Free hosting</li>
</ul>
<h3>Amazon S3</h3>
<ul>
<li>Stores input images and generated audio files</li>
<li>Provides public URLs for podcast distribution</li>
</ul>
<h3>GitHub Actions</h3>
<ul>
<li>Automates the entire pipeline</li>
<li>Runs on schedule to process new images</li>
</ul>
<h2>Key Takeaways</h2>
<p><strong>Start simple, then automate</strong>: The first version was just photos and text. Over time, I added illustrations, audio, and full automation.</p>
<p><strong>Prompt engineering matters</strong>: The constraints in my story generation prompt (avoiding certain words, specific paragraph counts) help maintain consistency across 1200+ stories.</p>
<p><strong>Multi-model pipeline works</strong>: Using GPT-4o for vision, GPT-5 for editing, GPT-4o-mini for prompt refinement, and DALL-E 3 for images creates better results than using a single model.</p>
<p><strong>RSS feeds unlock distribution</strong>: A simple XML file makes your content available on Spotify and all major podcast platforms without any special APIs.</p>
<p><strong>Automation scales</strong>: Once the pipeline was set up, I could process hundreds of stories without manual intervention. The GitHub Actions workflow handles everything.</p>
<p><strong>Real-world inspiration</strong>: Starting with a real problem (my son wanting stories) led to a project that now serves thousands of listeners.</p>
<h2>Video Walkthrough</h2>
<p>If you prefer to follow along in a code-along format, here's a video where I walk through the project and show my screen step by step:</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; margin: 2rem 0;">
  <iframe 
    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" 
    src="https://www.youtube.com/embed/DvhdJWqE47g" 
    frameborder="0" 
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
    allowfullscreen
    title="Kids Horror Stories AI Pipeline - Code Walkthrough">
  </iframe>
</div>
<h2>See It Live</h2>
<p>You can see the live project and the code here:</p>
<ul>
<li><strong>Website (Jekyll, GitHub Pages)</strong>: <a href="https://alexeygrigorev.com/kids-horror-stories-ru/">kids-horror-stories-ru</a></li>
<li><strong>GitHub repo</strong>: <a href="https://github.com/alexeygrigorev/kids-horror-stories-ru">github.com/alexeygrigorev/kids-horror-stories-ru</a></li>
<li><strong>Spotify</strong>: <a href="https://open.spotify.com/episode/0GOcZiMzHVIR4VZYEjTb8K?si=mf-3OkY0Q1aN2SSgu4zhfw">Listen to an episode on Spotify</a></li>
</ul>
<p>The project demonstrates how AI tools can create complete multimedia content pipelines—from a simple photo to a fully produced podcast episode—all automated and running at scale.</p>
0:{"buildId":"TJlvx0-THJMa2i_qu9SF5","rsc":["$","$1","c",{"children":[[["$","$L2",null,{}],["$","main",null,{"className":"min-h-screen pt-24","children":["$","article",null,{"className":"py-16 lg:py-24","children":["$","div",null,{"className":"mx-auto max-w-3xl px-6 lg:px-8","children":[["$","$L3",null,{"href":"/blog","className":"mb-8 inline-flex items-center gap-2 text-sm text-muted-foreground transition-colors hover:text-foreground","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-left h-4 w-4","aria-hidden":"true","children":[["$","path","1l729n",{"d":"m12 19-7-7 7-7"}],["$","path","x3x0zl",{"d":"M19 12H5"}],"$undefined"]}],"Back to Blog"]}],["$","header",null,{"className":"mb-12","children":[["$","h1",null,{"className":"text-balance text-3xl font-semibold tracking-tight sm:text-4xl lg:text-5xl","children":"How I Built a Fully Automated Image-to-Podcast Pipeline for Kids Horror Stories"}],["$","p",null,{"className":"mt-4 text-xl text-muted-foreground","children":"I built a fully automated system that takes photos of everyday objects and turns them into illustrated horror stories, complete with audio narration and Spotify podcast episodes. Here's how I did it."}],["$","div",null,{"className":"mt-6 flex flex-wrap items-center gap-4 text-sm text-muted-foreground","children":[["$","span",null,{"className":"flex items-center gap-1.5","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-calendar h-4 w-4","aria-hidden":"true","children":[["$","path","1cmpym",{"d":"M8 2v4"}],["$","path","4m81vk",{"d":"M16 2v4"}],["$","rect","1hopcy",{"width":"18","height":"18","x":"3","y":"4","rx":"2"}],["$","path","8toen8",{"d":"M3 10h18"}],"$undefined"]}],"December 12, 2025"]}],["$","span",null,{"className":"flex items-center gap-1.5","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-clock h-4 w-4","aria-hidden":"true","children":[["$","path","mmk7yg",{"d":"M12 6v6l4 2"}],["$","circle","1mglay",{"cx":"12","cy":"12","r":"10"}],"$undefined"]}],"11 min read"]}]]}],["$","div",null,{"className":"mt-4 flex flex-wrap gap-2","children":[["$","span","ai-tools",{"className":"rounded-full bg-secondary px-3 py-1 text-xs text-muted-foreground","children":"ai-tools"}],["$","span","podcast",{"className":"rounded-full bg-secondary px-3 py-1 text-xs text-muted-foreground","children":"podcast"}],["$","span","automation",{"className":"rounded-full bg-secondary px-3 py-1 text-xs text-muted-foreground","children":"automation"}],["$","span","gpt-4",{"className":"rounded-full bg-secondary px-3 py-1 text-xs text-muted-foreground","children":"gpt-4"}],["$","span","dall-e",{"className":"rounded-full bg-secondary px-3 py-1 text-xs text-muted-foreground","children":"dall-e"}],["$","span","tts",{"className":"rounded-full bg-secondary px-3 py-1 text-xs text-muted-foreground","children":"tts"}]]}]]}],["$","div",null,{"className":"$4","dangerouslySetInnerHTML":{"__html":"$5"}}]]}]}]}],"$L6"],["$L7","$L8"],"$L9"]}],"loading":null,"isPartial":false}
6:["$","footer",null,{"className":"border-t border-border bg-card","children":["$","div",null,{"className":"mx-auto max-w-7xl px-6 py-16 lg:px-8 lg:py-24","children":[["$","div",null,{"className":"mx-auto max-w-2xl text-center","children":[["$","h2",null,{"className":"text-balance text-2xl font-semibold tracking-tight sm:text-3xl","children":"Want to know when we launch?"}],["$","p",null,{"className":"mt-4 text-muted-foreground","children":"Subscribe to the free newsletter and get the first ping when the community opens."}],["$","div",null,{"className":"mt-8 flex justify-center","children":["$","div",null,{"className":"w-full max-w-md overflow-hidden rounded-lg border border-border bg-background","children":["$","iframe",null,{"src":"https://alexeyondata.substack.com/embed","width":"100%","height":"150","className":"block","style":{"border":0},"frameBorder":"0","scrolling":"no","title":"Newsletter sign up"}]}]}]]}],["$","div",null,{"className":"mt-16 grid gap-8 border-t border-border pt-8 sm:grid-cols-2 lg:grid-cols-4","children":[["$","div",null,{"children":[["$","div",null,{"className":"flex items-center gap-2","children":[["$","div",null,{"className":"h-6 w-6 rounded bg-accent"}],["$","span",null,{"className":"font-semibold","children":"AI Engineering Lab"}]]}],["$","p",null,{"className":"mt-4 text-sm text-muted-foreground","children":"A technical community for AI, data, and engineering practitioners."}]]}],["$","div",null,{"children":[["$","h3",null,{"className":"text-sm font-semibold text-foreground","children":"Community"}],["$","ul",null,{"className":"mt-4 space-y-3","children":[["$","li",null,{"children":["$","$L3",null,{"href":"/about","className":"text-sm text-muted-foreground transition-colors hover:text-foreground","children":"About Alexey Grigorev"}]}],["$","li",null,{"children":["$","$L3",null,{"href":"/topics","className":"text-sm text-muted-foreground transition-colors hover:text-foreground","children":"Topics"}]}],["$","li",null,{"children":["$","$L3",null,{"href":"/#tiers","className":"text-sm text-muted-foreground transition-colors hover:text-foreground","children":"Membership Tiers"}]}],["$","li",null,{"children":["$","$L3",null,{"href":"/#faq","className":"text-sm text-muted-foreground transition-colors hover:text-foreground","children":"FAQ"}]}]]}]]}],["$","div",null,{"children":[["$","h3",null,{"className":"text-sm font-semibold text-foreground","children":"Connect"}],["$","ul",null,{"className":"mt-4 space-y-3","children":[["$","li",null,{"children":["$","a",null,{"href":"https://Alexey Grigorevondata.substack.com","target":"_blank","rel":"noopener noreferrer","className":"text-sm text-muted-foreground transition-colors hover:text-foreground","children":"Substack"}]}],["$","li",null,{"children":["$","a",null,{"href":"https://youtube.com/@datatalksclub","target":"_blank","rel":"noopener noreferrer","className":"text-sm text-muted-foreground transition-colors hover:text-foreground","children":"YouTube"}]}],["$","li",null,{"children":["$","a",null,{"href":"https://linkedin.com/in/agrigorev","target":"_blank","rel":"noopener noreferrer","className":"text-sm text-muted-foreground transition-colors hover:text-foreground","children":"LinkedIn"}]}],["$","li",null,{"children":["$","a",null,{"href":"https://datatalks.club","target":"_blank","rel":"noopener noreferrer","className":"text-sm text-muted-foreground transition-colors hover:text-foreground","children":"DataTalks.Club"}]}]]}]]}],["$","div",null,{"children":[["$","h3",null,{"className":"text-sm font-semibold text-foreground","children":"Legal"}],["$","ul",null,{"className":"mt-4 space-y-3","children":[["$","li",null,{"children":["$","$L3",null,{"href":"#","className":"text-sm text-muted-foreground transition-colors hover:text-foreground","children":"Privacy Policy"}]}],["$","li",null,{"children":["$","$L3",null,{"href":"#","className":"text-sm text-muted-foreground transition-colors hover:text-foreground","children":"Terms of Service"}]}]]}]]}]]}],["$","div",null,{"className":"mt-8 border-t border-border pt-8 text-center","children":["$","p",null,{"className":"text-sm text-muted-foreground","children":["© ",2026," AI Engineering Lab by Alexey Grigorev. All rights reserved."]}]}]]}]}]
7:["$","script","script-0",{"src":"/_next/static/chunks/311667441357723c.js","async":true}]
8:["$","script","script-1",{"src":"/_next/static/chunks/5565ce82c1f7fdab.js","async":true}]
9:["$","$La",null,{"children":["$","$b",null,{"name":"Next.MetadataOutlet","children":"$@c"}]}]
c:null
